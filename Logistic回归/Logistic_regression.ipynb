{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置映射字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {}\n",
    "x_string = 'ARNDCQEGHILKMFPSTWYV'\n",
    "for i in range(len(x_string)):\n",
    "    key = x_string[i]\n",
    "    value = i + 1\n",
    "    x_dict[key] = value\n",
    "    \n",
    "y_dict = {1:1, -1:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取文件函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    with open(file) as f:\n",
    "        for line in f.readlines():\n",
    "            x, y = line.strip().split(',')\n",
    "            x_list = [x_dict[i] for i in x]\n",
    "            data_x.append(x_list)\n",
    "            data_y.append(int(y))\n",
    "            \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取所有数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_765 = './newHIV-1_data/746Data.txt'\n",
    "file_1625 = './newHIV-1_data/1625Data.txt'\n",
    "file_impens = './newHIV-1_data/impensData.txt'\n",
    "file_schilling = './newHIV-1_data/schillingData.txt'\n",
    "\n",
    "data_765_x, data_765_y = read_file(file_765)\n",
    "data_1625_x, data_1625_y = read_file(file_1625)\n",
    "data_impens_x, data_impens_y = read_file(file_impens)\n",
    "data_schilling_x, data_schilling_y = read_file(file_schilling)\n",
    "\n",
    "data_dict_x = {}\n",
    "data_dict_y = {}\n",
    "data_dict_x['765'], data_dict_y['765'] = data_765_x, data_765_y\n",
    "data_dict_x['1625'], data_dict_y['1625'] = data_1625_x, data_1625_y\n",
    "data_dict_x['impens'], data_dict_y['impens'] = data_impens_x, data_impens_y\n",
    "data_dict_x['schilling'], data_dict_y['schilling'] = data_schilling_x, data_schilling_y\n",
    "\n",
    "data_set = ['765', '1625', 'impens', 'schilling']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调包实现Logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_package(training_set, dataset, data_dict_x, data_dict_y):\n",
    "    testing_set = dataset[:]\n",
    "    testing_set.remove(training_set)\n",
    "    x_train, y_train = data_dict_x[training_set], data_dict_y[training_set]\n",
    "    x_test, y_test = data_dict_x[testing_set[0]], data_dict_y[testing_set[0]]\n",
    "    for i in range(2):\n",
    "        x_test = x_test + data_dict_x[testing_set[i+1]]\n",
    "        y_test = y_test + data_dict_y[testing_set[i+1]]\n",
    "    \n",
    "    clf = LogisticRegressionCV(multi_class=\"ovr\", cv=2, penalty=\"l2\", solver=\"sag\", tol=0.01)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(\"report: \", report)\n",
    "#     print(\"acc: \", acc)\n",
    "    print(\"auc: \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分别以一个数据集作为训练集并在其他三个数据集上做测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.61      0.72      4886\n",
      "           1       0.22      0.55      0.31       958\n",
      "\n",
      "    accuracy                           0.60      5844\n",
      "   macro avg       0.55      0.58      0.52      5844\n",
      "weighted avg       0.77      0.60      0.65      5844\n",
      "\n",
      "auc:  0.582604467452916\n"
     ]
    }
   ],
   "source": [
    "training_set = '765'\n",
    "Logistic_package(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      1.00      0.89      3980\n",
      "           1       0.73      0.01      0.02       985\n",
      "\n",
      "    accuracy                           0.80      4965\n",
      "   macro avg       0.77      0.50      0.45      4965\n",
      "weighted avg       0.79      0.80      0.72      4965\n",
      "\n",
      "auc:  0.5036840292834731\n"
     ]
    }
   ],
   "source": [
    "training_set = '1625'\n",
    "Logistic_package(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      1.00      0.88      4432\n",
      "           1       0.00      0.00      0.00      1211\n",
      "\n",
      "    accuracy                           0.79      5643\n",
      "   macro avg       0.39      0.50      0.44      5643\n",
      "weighted avg       0.62      0.79      0.69      5643\n",
      "\n",
      "auc:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lupapa/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "training_set = 'impens'\n",
    "Logistic_package(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      1.00      0.84      2392\n",
      "           1       0.00      0.00      0.00       926\n",
      "\n",
      "    accuracy                           0.72      3318\n",
      "   macro avg       0.36      0.50      0.42      3318\n",
      "weighted avg       0.52      0.72      0.60      3318\n",
      "\n",
      "auc:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lupapa/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "training_set = 'schilling'\n",
    "Logistic_package(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手写Logistic回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logis():\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0 / (1 + np.exp(-z))\n",
    "    \n",
    "    def train(self, data, label):\n",
    "        m, n = np.shape(data)\n",
    "        maxCycles = 200\n",
    "        weights = np.ones(n)\n",
    "        for cycle in range(maxCycles):\n",
    "            dataIndex=list(range(m))\n",
    "            for i in range(m):\n",
    "                alpha = 4 / (1.0 + cycle + i) + 0.01\n",
    "                randIndex=int(np.random.uniform(0, len(dataIndex)))\n",
    "                y = self.sigmoid(sum(data[randIndex] * weights ))\n",
    "                error = label[randIndex] - y\n",
    "                weights = weights + alpha  * error * data[randIndex]\n",
    "                del(dataIndex[randIndex])\n",
    "                # print(type(weights))\n",
    "        return weights\n",
    "    \n",
    "    def predict(self, data, weights):\n",
    "        m, n = np.shape(data)\n",
    "        y_pred = []\n",
    "        for i in range(m):\n",
    "            y = self.sigmoid(sum(data[i] * weights))\n",
    "            if y > 0.5:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_write(training_set, dataset, data_dict_x, data_dict_y):\n",
    "    testing_set = dataset[:]\n",
    "    testing_set.remove(training_set)\n",
    "    x_train, y_train = data_dict_x[training_set], data_dict_y[training_set]\n",
    "    x_test, y_test = data_dict_x[testing_set[0]], data_dict_y[testing_set[0]]\n",
    "    for i in range(2):\n",
    "        x_test = x_test + data_dict_x[testing_set[i+1]]\n",
    "        y_test = y_test + data_dict_y[testing_set[i+1]]\n",
    "    \n",
    "    y_train = [y_dict[i] for i in y_train]\n",
    "    y_test = [y_dict[i] for i in y_test]\n",
    "    \n",
    "    clf = Logis()\n",
    "    weights = clf.train(np.array(x_train), y_train)\n",
    "    y_pred = clf.predict(np.array(x_test), weights)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    print(\"report: \", report)\n",
    "#     print(\"acc: \", acc)\n",
    "    print(\"auc: \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分别以一个数据集作为训练集并在其他三个数据集上做测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4886\n",
      "           1       0.00      0.00      0.00       958\n",
      "\n",
      "    accuracy                           0.84      5844\n",
      "   macro avg       0.42      0.50      0.46      5844\n",
      "weighted avg       0.70      0.84      0.76      5844\n",
      "\n",
      "auc:  0.4993860008186656\n"
     ]
    }
   ],
   "source": [
    "training_set = '765'\n",
    "Logistic_write(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.03      0.06      3980\n",
      "           1       0.20      0.97      0.33       985\n",
      "\n",
      "    accuracy                           0.21      4965\n",
      "   macro avg       0.49      0.50      0.19      4965\n",
      "weighted avg       0.66      0.21      0.11      4965\n",
      "\n",
      "auc:  0.49731398107287705\n"
     ]
    }
   ],
   "source": [
    "training_set = '1625'\n",
    "Logistic_write(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86      4432\n",
      "           1       0.25      0.06      0.09      1211\n",
      "\n",
      "    accuracy                           0.76      5643\n",
      "   macro avg       0.52      0.51      0.48      5643\n",
      "weighted avg       0.67      0.76      0.70      5643\n",
      "\n",
      "auc:  0.5056616619018802\n"
     ]
    }
   ],
   "source": [
    "training_set = 'impens'\n",
    "Logistic_write(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      2392\n",
      "           1       0.27      0.18      0.22       926\n",
      "\n",
      "    accuracy                           0.63      3318\n",
      "   macro avg       0.49      0.50      0.49      3318\n",
      "weighted avg       0.59      0.63      0.61      3318\n",
      "\n",
      "auc:  0.4959697371367481\n"
     ]
    }
   ],
   "source": [
    "training_set = 'schilling'\n",
    "Logistic_write(training_set, data_set, data_dict_x, data_dict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 样本不均衡问题：损失做操作，采样\n",
    "- 编码问题（标签编码，one-hot编码）：目标编码、证据权重（WOE）\n",
    "- 证据权重\n",
    "- 指标问题：auc\n",
    "- 先探索数据\n",
    "- 验证集\n",
    "- 超参数调整\n",
    "- 损失函数的选择问题"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
